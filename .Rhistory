Hcol_index <- vec[2]
row2 <- (Hrow_index + 1) / 2 + 1
col2 <- (Hcol_index + 1) / 2 + 1
cent_value <- img2[row2, col2]
return(c(img[Hrow_index, Hcol_index, ch] - cent_value,
img[Hrow_index, Hcol_index + 1, ch] - cent_value,
img[Hrow_index + 1, Hcol_index, ch] - cent_value,
img[Hrow_index + 1, Hcol_index + 1, ch] - cent_value))
}
test <- function(a = 3){
return(list("test1" = c(a, a+1), "test2" = c(a+2, a)))
}
#######################
feature <- function(LR_dir, HR_dir, n_points=100){
### Construct process features for traini3ng images (LR/HR pairs)
### Input: a path for low-resolution images + a path for high-resolution images
###        + number of points sampled from each LR image
### Output: an .RData file contains processed features and responses for the images
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir)) # 1500
### store feature and responses
featMat <- array(NA, c(n_files * n_points, 8, 3))
labMat <- array(NA, c(n_files * n_points, 4, 3))
### read LR/HR image pairs
for(i in c(1:3)){
#i = 2
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
LR_nrow <- nrow(imgLR)
LR_ncol <- ncol(imgLR)
HR_nrow <- nrow(imgHR)
HR_ncol <- ncol(imgHR)
### step 3. For three channels
for (k in c(1:3)) {
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
sampled_locations <- t(sapply(sampled_points, locate, LR_ncol)) # locations in the imgLR matrix
HR_locations <- 2 * sampled_locations - 1  # corresponding locations in the imgHR matrix
new_locations <- sampled_locations + 1 # locations in the supp matrix
# supplement the image matrix
supp_imgLR <- cbind(imgLR[, 1, k], imgLR[, , k], imgLR[, LR_ncol, k])
supp_imgLR <- rbind(cbind(imgLR[1, 1, k], imgLR[1, , k],imgLR[1, LR_ncol, k]),
supp_imgLR, cbind(imgLR[LR_nrow, 1, k], imgLR[LR_nrow, , k],imgLR[LR_nrow, LR_ncol, k]))
### step 2. for each sampled point in imgLR
######## optimization computation (vectorization)
featMat[((i - 1) * n_points + 1) : ((i - 1) * n_points + n_points),  , k] <- t(apply(new_locations, 1, distribute1, img = supp_imgLR))
labMat[((i - 1) * n_points + 1) : ((i - 1) * n_points + n_points),  , k] <- t(apply(HR_locations, 1, distribute2, img = imgHR, img2 = supp_imgLR, ch = k))
#########
print(paste("k = ", k, sep = ""))
#
#   for (j in 1:n_points) {
#
#     ### step 2.1. save (the neighbor 8 pixels - central pixel) in featMat
#     row_index <- new_locations[[j]][1]
#     col_index <- new_locations[[j]][2]
#     cent_value <- supp_imgLR[row_index, col_index]
#     featMat[(i - 1) * n_points + j, , k] <- c(supp_imgLR[row_index - 1, col_index - 1] - cent_value,
#                                               supp_imgLR[row_index - 1, col_index] - cent_value,
#                                               supp_imgLR[row_index - 1, col_index + 1] - cent_value,
#                                               supp_imgLR[row_index, col_index - 1] - cent_value,
#                                               supp_imgLR[row_index, col_index + 1] - cent_value,
#                                               supp_imgLR[row_index + 1, col_index - 1] - cent_value,
#                                               supp_imgLR[row_index + 1, col_index] - cent_value,
#                                               supp_imgLR[row_index + 1, col_index + 1] - cent_value)
#
#     ### step 2.2. save the corresponding 4 sub-pixels of imgHR in labMat
#     Hrow_index <- HR_locations[[j]][1]
#     Hcol_index <- HR_locations[[j]][2]
#     labMat[(i - 1) * n_points + j, , k] <- c(imgHR[Hrow_index, Hcol_index, k] - cent_value,
#                                              imgHR[Hrow_index, Hcol_index + 1, k] - cent_value,
#                                              imgHR[Hrow_index + 1, Hcol_index, k] - cent_value,
#                                              imgHR[Hrow_index + 1, Hcol_index + 1, k] - cent_value)
#
#   }
#
#
}
print(paste("i = ", i, sep = ""))
}
return(list(feature = featMat, label = labMat))
}
Sys.time()
output = feature(LR_dir, HR_dir, n_points=100)
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
setwd("../")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
set.seed(2018)
setwd("../")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
tm_feature_train
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
tm_feature_train
#i = 2
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
i = 1
#i = 2
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
LR_nrow <- nrow(imgLR)
LR_ncol <- ncol(imgLR)
HR_nrow <- nrow(imgHR)
HR_ncol <- ncol(imgHR)
LR_nrow
HR_nrow
LR_ncol
HR_ncol
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
#i = 2
imgLR <- readImage(paste0(LR_dir,  "img_", sprintf("%04d", i), ".jpg"))
imgHR <- readImage(paste0(HR_dir,  "img_", sprintf("%04d", i), ".jpg"))
LR_nrow <- nrow(imgLR)
LR_ncol <- ncol(imgLR)
HR_nrow <- 2 * LR_nrow
HR_ncol <- 2 * LR_ncol
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
sampled_locations <- t(sapply(sampled_points, locate, LR_ncol)) # locations in the imgLR matrix
HR_locations <- 2 * sampled_locations - 1  # corresponding locations in the imgHR matrix
new_locations <- sampled_locations + 1 # locations in the supp matrix
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
tm_feature_train
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
### step 1
tm_feature_train
source("../lib/train.R")
source("../lib/test.R")
model_labels
array(dim=c(length(model_values), 2))
array(dim=c(length(model_values), 2))
model_values
k = 1
cat("k=", k, "\n")
source("../lib/cross_validation.R")
if(run.cv){
err_c
v <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
source("../lib/cross_validation.R")
if(run.cv){
err_c
v <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k], k)
}
save(err_cv, file="../output/err_cv.RData")
}
rm(list = ls())
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
set.seed(2018)
setwd("../")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_LR_dir <- paste(train_dir, "LR/", sep="")
train_HR_dir <- paste(train_dir, "HR/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
extra_label <- read.csv(train_label_path, colClasses=c("NULL", NA, NA))
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(train_LR_dir, train_HR_dir))
feat_train <- dat_train$feature
label_train <- dat_train$label
}
#save(dat_train, file="./output/feature_train.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(feat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(depth=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(feat_train, label_train, par_best))
save(fit_train, file="../output/fit_train.RData")
source("../lib/superResolution.R")
test_dir <- "../data/test_set/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_train.RData")
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
source("../lib/superResolution.R")
test_dir <- "../data/test_set/" # This will be modified for different data sets.
test_LR_dir <- paste(test_dir, "LR/", sep="")
test_HR_dir <- paste(test_dir, "HR/", sep="")
tm_test=NA
if(run.test){
load(file="../output/fit_train.RData")
tm_test <- system.time(superResolution(test_LR_dir, test_HR_dir, fit_train))
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
model_values
X.train = feat_train
y.train = label_train
n <- dim(y.train)[1]
n
n.fold <- floor(n/K)
n.fold
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
s
c(rep(n.fold, K-1), n-(K-1)*n.fold)
cv.error <- rep(NA, K)
cv.error
d = 3
par <- list(depth=d)
par
err_cv
par_best
model_values
tm_train
par
3%%4
3 %% 4
3 % % 4
1 %% 4
5 %% 4
9 %% 4
11 %% 4
### load libraries
library("EBImage")
n_files <- length(list.files(LR_dir))
n_files
i
i = 1
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", i), ".jpg"))
imgLR
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", i), ".jpg")
pathHR
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
featMat
dim(feat_train)
dim(imgLR)
dim(imgLR)[1] * dim(imgLR)[2]
featMat <- array(NA, c(dim(imgLR)[1] * dim(imgLR)[2], 8, 3))
dim(featMat)
dim(featMat)
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
LR_nrow <- nrow(imgLR)
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
LR_ncol <- ncol(imgLR)
### step 1. sample n_points frolm imgLR
sampled_points <- sample(LR_nrow * LR_ncol, n_points)
sampled_points
1:600
test_LR_dir
imgLR
pathHR
dim(featMat)
LR_nrow <- nrow(imgLR)
LR_ncol <- ncol(imgLR)
featMat <- array(NA, c(LR_nrow * LR_ncol, 8, 3))
dim(featMat)
locate
1 : num_ele
num_ele <- LR_nrow * LR_ncol
featMat <- array(NA, c(num_ele, 8, 3))
dim
dim(featMat)
1 : num_ele
t(sapply(1 : num_ele, locate, LR_ncol))
ele_locations <- t(sapply(1 : num_ele, locate, LR_ncol)) * 1
ele_locations
dim(featMat)
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
ele_locations <- t(sapply(1 : num_ele, locate, LR_ncol))
ele_locations
dim(ele_locations)
dim(featMat)
ele_locations
new_locations <- ele_locations + 1
new_locations
ele_locations
dim(new_locations)
k = 1
# supplementary image matrix
supp_imgLR <- cbind(imgLR[, 1, k], imgLR[, , k], imgLR[, LR_ncol, k])
supp_imgLR <- rbind(cbind(imgLR[1, 1, k], imgLR[1, , k],imgLR[1, LR_ncol, k]),
supp_imgLR, cbind(imgLR[LR_nrow, 1, k], imgLR[LR_nrow, , k],imgLR[LR_nrow, LR_ncol, k]))
dim(supp_imgLR)
286*217
dim(imgLR)
284*215
### fill the featM
featMat[,  , k] <- t(apply(new_locations, 1, distribute1, img = supp_imgLR))
featMat
i
n_files <- length(list.files(LR_dir))
imgLR <- readImage(paste0(LR_dir,  "img", "_", sprintf("%04d", i), ".jpg"))
pathHR <- paste0(HR_dir,  "img", "_", sprintf("%04d", i), ".jpg")
LR_nrow <- nrow(imgLR)
LR_ncol <- ncol(imgLR)
num_ele <- LR_nrow * LR_ncol
featMat <- array(NA, c(num_ele, 8, 3))
### step 1. for each pixel and each channel in imgLR:
###           save (the neighbor 8 pixels - central pixel) in featMat
###           tips: padding zeros for boundary points
ele_locations <- t(sapply(1 : num_ele, locate, LR_ncol))
new_locations <- ele_locations + 1
for (k in c(1:3)) {
# supplementary image matrix
supp_imgLR <- cbind(imgLR[, 1, k], imgLR[, , k], imgLR[, LR_ncol, k])
supp_imgLR <- rbind(cbind(imgLR[1, 1, k], imgLR[1, , k],imgLR[1, LR_ncol, k]),
supp_imgLR, cbind(imgLR[LR_nrow, 1, k], imgLR[LR_nrow, , k],imgLR[LR_nrow, LR_ncol, k]))
### fill the featM
featMat[,  , k] <- t(apply(new_locations, 1, distribute1, img = supp_imgLR))
#########
#print(paste("k = ", k, sep = ""))
}
### step 2. apply the modelList over featMat
predMat <- test(modelList, featMat)
fit_train
### step 2. apply the modelList over featMat
predMat <- test(fit_train, featMat)
predMat
dim(predMat)
### step 2. apply the modelList over featMat
predMat <- test(modelList, featMat)
### step 2. apply the modelList over featMat
predMat <- test(modelList = fit_train, featMat)
predMat
dim(predMat)
clahe(predMat)
length(predMat)
nrow(imgLR) * ncol(imgLR)
nrow(imgLR) * ncol(imgLR)*3*2
nrow(imgLR) * ncol(imgLR)*3*2*2
######################################################
### Fit the regression model with testing data ###
######################################################
### Author: Chengliang Tang
### Project 3
test <- function(modelList, dat_test){
### Fit the classfication model with testing data
### Input:
###  - the fitted classification model list using training data
###  - processed features from testing images
### Output: training model specification
### load libraries
library("gbm")
predArr <- array(NA, c(dim(dat_test)[1], 4, 3))
for (i in 1:12){
fit_train <- modelList[[i]]
### calculate column and channel
c1 <- (i-1) %% 4 + 1
c2 <- (i-c1) %/% 4 + 1
featMat <- dat_test[ , , c2]
### make predictions
predArr[, c1, c2] <- predict(fit_train$fit, newdata=featMat,
n.trees=fit_train$iter, type="response")
}
return(predArr)
}
### step 2. apply the modelList over featMat
predMat <- test(modelList = fit_train, featMat)
predMat
dim(predMat)
as.numeric(predMat)
class(predMat)
dim(predMat)
predMat[1:3, 1:3, ]
as.numeric(predMat[1:3, 1:3, ])
as.numeric(predMat[1:3, 1:4, ])
as.numeric(predMat[1:3, 1:4, ])
as.numeric(predMat[1:3, 1:4, ])
as.numeric(predMat[1:3, 1:4, ])
predMat[1:3, 1:4, ]
as.numeric(predMat[1:3, 1:4, ])
dim(predMat)
